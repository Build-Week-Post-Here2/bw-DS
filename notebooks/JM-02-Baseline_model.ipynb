{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_DATA_PATH = pathlib.Path.cwd().parent / \"data\" / \"external\" / \"reddit-selfposts\" / \"reddit.tsv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(KAGGLE_DATA_PATH, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012995</th>\n",
       "      <td>5r9k4h</td>\n",
       "      <td>MSLGame</td>\n",
       "      <td>Is this months rebirth and dungeon astro's wor...</td>\n",
       "      <td>I looking on what to evo3 farm next and was ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012996</th>\n",
       "      <td>6529fp</td>\n",
       "      <td>CrohnsDisease</td>\n",
       "      <td>I might need a Medical leave from grad school</td>\n",
       "      <td>Has anyone here ever needed a medical leave fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012997</th>\n",
       "      <td>7tiyzx</td>\n",
       "      <td>HongKong</td>\n",
       "      <td>Police harassing ethnic minorities in Hong Kong</td>\n",
       "      <td>I thought I'd make this post so that more peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012998</th>\n",
       "      <td>664ha3</td>\n",
       "      <td>yorku</td>\n",
       "      <td>SU EECS 2030 and EECS 2021 - need advice</td>\n",
       "      <td>Hi, I just finished 1st year EECS courses and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012999</th>\n",
       "      <td>6ump0y</td>\n",
       "      <td>wine</td>\n",
       "      <td>What is the worse wine you ever had?</td>\n",
       "      <td>My worst wine was at a dinner party. My friend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id             subreddit  \\\n",
       "0        6d8knd  talesfromtechsupport   \n",
       "1        58mbft               teenmom   \n",
       "2        8f73s7                Harley   \n",
       "3        6ti6re          ringdoorbell   \n",
       "4        77sxto                 intel   \n",
       "...         ...                   ...   \n",
       "1012995  5r9k4h               MSLGame   \n",
       "1012996  6529fp         CrohnsDisease   \n",
       "1012997  7tiyzx              HongKong   \n",
       "1012998  664ha3                 yorku   \n",
       "1012999  6ump0y                  wine   \n",
       "\n",
       "                                                     title  \\\n",
       "0                   Remember your command line switches...   \n",
       "1                          So what was Matt \"addicted\" to?   \n",
       "2                                           No Club Colors   \n",
       "3              Not door bell, but floodlight mount height.   \n",
       "4        Worried about my 8700k small fft/data stress r...   \n",
       "...                                                    ...   \n",
       "1012995  Is this months rebirth and dungeon astro's wor...   \n",
       "1012996      I might need a Medical leave from grad school   \n",
       "1012997    Police harassing ethnic minorities in Hong Kong   \n",
       "1012998           SU EECS 2030 and EECS 2021 - need advice   \n",
       "1012999               What is the worse wine you ever had?   \n",
       "\n",
       "                                                  selftext  \n",
       "0        Hi there,  <lb>The usual. Long time lerker, fi...  \n",
       "1        Did he ever say what his addiction was or is h...  \n",
       "2        Funny story. I went to college in Las Vegas. T...  \n",
       "3        I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4        Prime95 (regardless of version) and OCCT both,...  \n",
       "...                                                    ...  \n",
       "1012995  I looking on what to evo3 farm next and was ex...  \n",
       "1012996  Has anyone here ever needed a medical leave fr...  \n",
       "1012997  I thought I'd make this post so that more peop...  \n",
       "1012998  Hi, I just finished 1st year EECS courses and ...  \n",
       "1012999  My worst wine was at a dinner party. My friend...  \n",
       "\n",
       "[1013000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I fell asleep watching the Fantastic Beast movie so I’m guessing it wasn’t great.  I feel like it would be really well adapted into a TV show (not much knowledge on media rights).  Each chapter would be an episode and use different characters to show the discovery or a crazy moment involving the creature.  '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['selftext'][42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.1, replace=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101300, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81040, 4), (20260, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(sample, test_size=0.2, stratify=sample[\"subreddit\"])\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81040,) (20260,)\n",
      "(81040,) (20260,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[\"selftext\"]\n",
    "X_test = test[\"selftext\"]\n",
    "\n",
    "y_train = train[\"subreddit\"]\n",
    "y_test = test[\"subreddit\"]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729618    Previous owner had roof replaced/repaired not ...\n",
       "326284    Bought this for my partner as a valentines' gi...\n",
       "541065    This is sensational! my friends and I will lau...\n",
       "922717    hi <lb>first i'm F2P i played this game since ...\n",
       "287615    I have a BS degree in Civil Engineering from a...\n",
       "Name: selftext, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729618          RealEstate\n",
       "326284      whatsthisplant\n",
       "541065             shrooms\n",
       "922717    CaptainTsubasaDT\n",
       "287615    civilengineering\n",
       "Name: subreddit, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([300, 993, 862,  62, 519, 183,  50, 380])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the target using LabelEncoder\n",
    "\n",
    "le = LabelEncoder()  \n",
    "le.fit(y_train)  \n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test  = le.transform(y_test)\n",
    "\n",
    "y_train[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "To do:\n",
    "  \n",
    "- Vectorize the data - TfidfVectorizer\n",
    "> convert the words into numbers\n",
    "\n",
    "- topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '20', '2016', '2017', '24', '25', '30', '40', '50', '60', 'ability', 'able', 'absolutely', 'access', 'account', 'action', 'active', 'actual', 'actually', 'add', 'added', 'address', 'advance', 'advice', 'age', 'ago', 'air', 'album', 'allow', 'allowed', 'amazing', 'amazon', 'amp', 'amp nbsp', 'answer', 'answers', 'anxiety', 'anybody', 'anymore', 'anyways', 'app', 'apparently', 'apply', 'appreciate', 'appreciated', 'area', 'aren', 'art', 'ask', 'asked', 'asking', 'assume', 'attack', 'available', 'average', 'avoid', 'aware', 'away', 'awesome', 'baby', 'background', 'bad', 'ball', 'bar', 'base', 'based', 'basic', 'basically', 'bed', 'beginning', 'believe', 'best', 'better', 'big', 'bit', 'black', 'block', 'blood', 'blue', 'board', 'body', 'book', 'books', 'bought', 'box', 'brand', 'break', 'bring', 'brother', 'brought', 'budget', 'build', 'building', 'built', 'bunch', 'business', 'button', 'buy', 'buying', 'called', 'came', 'car', 'card', 'cards', 'care', 'career', 'case', 'cat', 'cause', 'certain', 'chance', 'change', 'changed', 'changes', 'character', 'characters', 'cheap', 'check', 'checked', 'child', 'children', 'choice', 'choose', 'city', 'class', 'classes', 'clean', 'clear', 'clearly', 'click', 'close', 'code', 'cold', 'college', 'color', 'com', 'com watch', 'come', 'comes', 'coming', 'comment', 'comments', 'common', 'community', 'company', 'complete', 'completely', 'computer', 'confused', 'consider', 'considering', 'constantly', 'contact', 'content', 'continue', 'control', 'cool', 'core', 'correct', 'cost', 'couldn', 'country', 'couple', 'course', 'cover', 'crazy', 'create', 'created', 'credit', 'curious', 'current', 'currently', 'cut', 'dad', 'daily', 'damage', 'dark', 'data', 'date', 'day', 'days', 'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'deck', 'deep', 'definitely', 'degree', 'design', 'despite', 'details', 'device', 'did', 'didn', 'die', 'difference', 'different', 'difficult', 'directly', 'doctor', 'does', 'does know', 'doesn', 'doing', 'don', 'don know', 'don really', 'don think', 'don want', 'dont', 'door', 'double', 'dr', 'dream', 'drink', 'drive', 'driving', 'drop', 'early', 'earth', 'easier', 'easily', 'easy', 'eat', 'eating', 'edit', 'effect', 'effects', 'email', 'end', 'ended', 'energy', 'english', 'enjoy', 'entire', 'episode', 'episodes', 'error', 'especially', 'event', 'events', 'eventually', 'exactly', 'example', 'excited', 'expect', 'expensive', 'experience', 'experienced', 'experiences', 'explain', 'extra', 'extremely', 'eye', 'eyes', 'face', 'facebook', 'fact', 'fairly', 'fall', 'family', 'fan', 'far', 'fast', 'father', 'favorite', 'feedback', 'feel', 'feel like', 'feeling', 'feels', 'feels like', 'felt', 'field', 'fight', 'figure', 'figured', 'file', 'files', 'final', 'finally', 'finding', 'fine', 'finish', 'finished', 'fit', 'fix', 'floor', 'focus', 'follow', 'following', 'food', 'force', 'form', 'forward', 'free', 'friend', 'friends', 'fuck', 'fucking', 'fully', 'fun', 'future', 'game', 'games', 'gave', 'gear', 'general', 'generally', 'gets', 'getting', 'girl', 'girls', 'given', 'gives', 'giving', 'goal', 'god', 'goes', 'going', 'gone', 'gonna', 'good', 'google', 'got', 'gotten', 'great', 'greatly', 'greatly appreciated', 'green', 'group', 'gt', 'gt lb', 'guess', 'guy', 'guys', 'guys lb', 'hair', 'half', 'hand', 'handle', 'hands', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'hasn', 'hate', 'haven', 'having', 'head', 'health', 'hear', 'heard', 'heart', 'heavy', 'hell', 'hello', 'hello lb', 'help', 'help lb', 'helped', 'helpful', 'helps', 'hey', 'hey guys', 'hi', 'hi lb', 'high', 'higher', 'history', 'hit', 'hold', 'home', 'honestly', 'hope', 'hopefully', 'hoping', 'hot', 'hour', 'hours', 'house', 'html', 'http', 'http imgur', 'http www', 'https', 'https imgur', 'https www', 'huge', 'human', 'hurt', 'husband', 'id', 'idea', 'ideas', 'im', 'image', 'images', 'imagine', 'imgur', 'imgur com', 'immediately', 'important', 'improve', 'include', 'including', 'info', 'information', 'input', 'inside', 'instead', 'interested', 'interesting', 'internet', 'interview', 'isn', 'issue', 'issues', 'item', 'items', 'ive', 'job', 'join', 'jpg', 'just', 'just got', 'just want', 'just wanted', 'keeping', 'kept', 'key', 'kid', 'kids', 'kill', 'killed', 'kind', 'kinda', 'knew', 'know', 'know lb', 'knowledge', 'known', 'knows', 'lack', 'language', 'large', 'late', 'later', 'lb', 'lb amp', 'lb did', 'lb does', 'lb don', 'lb edit', 'lb gt', 'lb help', 'lb http', 'lb https', 'lb just', 'lb know', 'lb lb', 'lb like', 'lb looking', 'lb question', 'lb really', 'lb tab', 'lb thank', 'lb thanks', 'lb think', 'lb ve', 'lb want', 'lead', 'learn', 'learned', 'learning', 'leave', 'leaving', 'left', 'let', 'let know', 'level', 'life', 'light', 'like', 'like lb', 'liked', 'likely', 'line', 'lines', 'link', 'list', 'listen', 'literally', 'little', 'live', 'living', 'll', 'local', 'lol', 'long', 'long time', 'longer', 'look', 'looked', 'looking', 'looks', 'looks like', 'lose', 'lost', 'lot', 'lots', 'love', 'loved', 'low', 'lower', 'lt', 'luck', 'machine', 'magic', 'main', 'major', 'make', 'make sure', 'makes', 'making', 'male', 'man', 'manager', 'map', 'market', 'match', 'matter', 'maybe', 'mean', 'means', 'media', 'meet', 'men', 'mention', 'mentioned', 'message', 'met', 'method', 'middle', 'miles', 'mind', 'minutes', 'miss', 'missing', 'mode', 'model', 'mom', 'moment', 'money', 'month', 'months', 'months ago', 'morning', 'mother', 'moved', 'movie', 'moving', 'multiple', 'music', 'nbsp', 'nbsp lb', 'near', 'need', 'needed', 'needs', 'net', 'network', 'new', 'news', 'nice', 'night', 'non', 'normal', 'normally', 'note', 'notice', 'noticed', 'number', 'numbers', 'obvious', 'obviously', 'offer', 'office', 'oh', 'ok', 'okay', 'old', 'older', 'ones', 'online', 'open', 'opinion', 'opinions', 'option', 'options', 'order', 'org', 'original', 'outside', 'overall', 'page', 'paid', 'pain', 'paper', 'parents', 'particular', 'parts', 'party', 'pass', 'past', 'pay', 'pc', 'people', 'perfect', 'period', 'person', 'personal', 'personally', 'phone', 'physical', 'pick', 'picked', 'picture', 'pictures', 'piece', 'place', 'places', 'plan', 'planning', 'play', 'played', 'player', 'players', 'playing', 'plus', 'pm', 'png', 'point', 'points', 'position', 'possible', 'possibly', 'post', 'posted', 'posting', 'posts', 'potential', 'power', 'practice', 'pre', 'prefer', 'pretty', 'previous', 'price', 'pro', 'probably', 'problem', 'problems', 'process', 'product', 'products', 'program', 'project', 'provide', 'public', 'pull', 'purchase', 'putting', 'quality', 'question', 'questions', 'quick', 'quickly', 'quite', 'random', 'range', 'rate', 'reach', 'read', 'reading', 'ready', 'real', 'realize', 'realized', 'really', 'really like', 'reason', 'reasons', 'received', 'recent', 'recently', 'recommend', 'recommendations', 'red', 'reddit', 'reddit com', 'regarding', 'regular', 'related', 'relationship', 'release', 'remember', 'remove', 'research', 'response', 'rest', 'result', 'results', 'return', 'right', 'road', 'room', 'round', 'rules', 'run', 'running', 'safe', 'said', 'save', 'saw', 'say', 'saying', 'says', 'scared', 'scene', 'school', 'screen', 'search', 'season', 'second', 'seconds', 'seeing', 'seen', 'self', 'sell', 'send', 'sense', 'sent', 'series', 'seriously', 'server', 'service', 'set', 'setting', 'settings', 'setup', 'sex', 'share', 'shit', 'shop', 'short', 'shot', 'shows', 'sign', 'similar', 'simple', 'simply', 'single', 'sister', 'site', 'sitting', 'situation', 'size', 'skills', 'skin', 'sleep', 'slightly', 'slow', 'small', 'social', 'software', 'solution', 'song', 'songs', 'soon', 'sorry', 'sort', 'sound', 'sounds', 'source', 'space', 'speak', 'special', 'specific', 'specifically', 'speed', 'spend', 'spent', 'spot', 'stand', 'standard', 'star', 'start', 'started', 'starting', 'starts', 'state', 'stay', 'step', 'stick', 'stop', 'stopped', 'store', 'stories', 'story', 'straight', 'strong', 'stuck', 'student', 'study', 'stuff', 'stupid', 'style', 'sub', 'subreddit', 'suggestions', 'summer', 'super', 'support', 'supposed', 'sure', 'switch', 'symptoms', 'tab', 'tab lb', 'tab tab', 'table', 'taken', 'takes', 'taking', 'talk', 'talking', 'tank', 'team', 'tell', 'telling', 'term', 'terms', 'test', 'text', 'thank', 'thanks', 'thanks advance', 'thanks lb', 'theory', 'thing', 'things', 'think', 'thinking', 'thought', 'thoughts', 'thread', 'throw', 'time', 'time lb', 'times', 'tips', 'tired', 'title', 'tl', 'tl dr', 'today', 'told', 'tomorrow', 'took', 'total', 'totally', 'touch', 'town', 'track', 'training', 'travel', 'tried', 'trip', 'trouble', 'true', 'try', 'trying', 'turn', 'turned', 'turns', 'tv', 'twice', 'type', 'uk', 'understand', 'understanding', 'unfortunately', 'university', 'unless', 'update', 'use', 'used', 'user', 'users', 'using', 'usually', 'value', 'various', 've', 've got', 've read', 've seen', 've tried', 'version', 'video', 'videos', 'view', 'voice', 'vs', 'wait', 'waiting', 'walk', 'wall', 'wallet', 'want', 'wanted', 'wanting', 'wants', 'war', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'wear', 'web', 'website', 'week', 'weekend', 'weeks', 'weight', 'weird', 'welcome', 'went', 'white', 'wife', 'willing', 'win', 'windows', 'wish', 'woman', 'women', 'won', 'wonder', 'wondering', 'word', 'words', 'work', 'work lb', 'worked', 'working', 'works', 'world', 'worried', 'worse', 'worst', 'worth', 'wouldn', 'write', 'writing', 'wrong', 'www', 'www reddit', 'www youtube', 'yeah', 'year', 'year old', 'years', 'years ago', 'yes', 'yesterday', 'young', 'youtube', 'youtube com', 'zero']\n"
     ]
    }
   ],
   "source": [
    "# Vectorize data\n",
    "\n",
    "vect = TfidfVectorizer(\n",
    "                    max_features=1000,\n",
    "                    min_df=1,\n",
    "                    ngram_range=(1, 2),\n",
    "                    stop_words='english'\n",
    ")\n",
    "\n",
    "# Learn vocabulary and idf, return term-document matrix.\n",
    "tdm = vect.fit_transform(X_train)\n",
    "\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(tdm.todense(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube com</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81035</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81037</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81040 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00       000   10  100        11   12   13       14   15   16  ...  \\\n",
       "0      0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "1      0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "2      0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "3      0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "4      0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "...    ...       ...  ...  ...       ...  ...  ...      ...  ...  ...  ...   \n",
       "81035  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.22676  0.0  0.0  ...   \n",
       "81036  0.0  0.082243  0.0  0.0  0.148102  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "81037  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "81038  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "81039  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.00000  0.0  0.0  ...   \n",
       "\n",
       "           year  year old     years  years ago  yes  yesterday  young  \\\n",
       "0      0.000000       0.0  0.237150        0.0  0.0        0.0    0.0   \n",
       "1      0.135125       0.0  0.130210        0.0  0.0        0.0    0.0   \n",
       "2      0.000000       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "3      0.000000       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "4      0.000000       0.0  0.062204        0.0  0.0        0.0    0.0   \n",
       "...         ...       ...       ...        ...  ...        ...    ...   \n",
       "81035  0.000000       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "81036  0.101520       0.0  0.195655        0.0  0.0        0.0    0.0   \n",
       "81037  0.272408       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "81038  0.000000       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "81039  0.000000       0.0  0.000000        0.0  0.0        0.0    0.0   \n",
       "\n",
       "       youtube  youtube com  zero  \n",
       "0          0.0          0.0   0.0  \n",
       "1          0.0          0.0   0.0  \n",
       "2          0.0          0.0   0.0  \n",
       "3          0.0          0.0   0.0  \n",
       "4          0.0          0.0   0.0  \n",
       "...        ...          ...   ...  \n",
       "81035      0.0          0.0   0.0  \n",
       "81036      0.0          0.0   0.0  \n",
       "81037      0.0          0.0   0.0  \n",
       "81038      0.0          0.0   0.0  \n",
       "81039      0.0          0.0   0.0  \n",
       "\n",
       "[81040 rows x 1000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                 metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# algorithm{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}\n",
    "nn = NearestNeighbors(n_neighbors=10, algorithm='brute', n_jobs=-1)\n",
    "\n",
    "# Fit the model on TFidf Vectors\n",
    "nn.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reddit.com/r/learnprogramming/comments/g99at4/i_printed_hello_world_in_cobol/\n",
    "\n",
    "test_input = \"\"\"\n",
    "I’m not much of a programmer, but when I saw that the world needs COBOL programmers right now, \n",
    "I thought I would do my best to help out, even though I knew nothing about the language. I’ve \n",
    "spent way too many hours over the past two weeks trying to get my system configured just to \n",
    "compile and run COBOL code. It might not seem like a big deal, but seeing those two words on \n",
    "the system output makes me feel like I can do anything!\n",
    "\"\"\"\n",
    "\n",
    "test_sparse = vect.transform([test_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 1.17545605, 1.18267843, 1.18894129, 1.18932033,\n",
       "         1.19187979, 1.19381911, 1.19750593, 1.19750593, 1.1993946 ]]),\n",
       " array([[61881, 12118, 48449, 32744, 41322, 54627, 13228, 49087, 42154,\n",
       "          5260]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array = nn.kneighbors(test_sparse.todense(), n_neighbors=10)\n",
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61881, 12118, 48449, 32744, 41322, 54627, 13228, 49087, 42154,\n",
       "        5260])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_id_list = test_array[1][0]\n",
    "rec_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = data.iloc[rec_id_list][\"subreddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61881            learnpython\n",
       "12118              indonesia\n",
       "48449         CoDCompetitive\n",
       "32744           communism101\n",
       "41322            danganronpa\n",
       "54627                 cancer\n",
       "13228                lebanon\n",
       "49087         SCREENPRINTING\n",
       "42154    KingkillerChronicle\n",
       "5260             techsupport\n",
       "Name: subreddit, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_two = \"\"\"\n",
    "\n",
    "Michael Jordan on Isiah Thomas: \"Whatever he says now, you know it wasn't his true actions then. \n",
    "He's had time to think about it. Or, the reaction of the public, that's kind of changed his \n",
    "perspective of it. You can show me anything you want. There's no way you can convince me he wasn't an asshole.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(req, n=10):\n",
    "    \"\"\"Function to recommend top n subreddits given a request.\"\"\"\n",
    "    # Create vector from request\n",
    "    req_vec = vect.transform([req])\n",
    "\n",
    "    # Get indexes for n nearest neighbors\n",
    "    top_id = nn.kneighbors(req_vec.todense(), n_neighbors=n)[1][0]\n",
    "\n",
    "    # Index-locate the neighbors in original dataframe\n",
    "    top_array = data.iloc[top_id][\"subreddit\"]\n",
    "\n",
    "    return top_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61881      learnpython\n",
       "30640             tall\n",
       "66617          Stellar\n",
       "78390        optometry\n",
       "66999    crossdressing\n",
       "50738          Cuckold\n",
       "58302        photoshop\n",
       "63971           German\n",
       "63749     amateurradio\n",
       "21173      musictheory\n",
       "Name: subreddit, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = recommend(post_two)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def picklizer():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
