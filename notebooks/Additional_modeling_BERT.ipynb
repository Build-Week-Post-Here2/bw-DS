{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Additional modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMj-z5GESanq",
        "colab_type": "code",
        "outputId": "09fb44d2-8514-4df4-f889-4e2d7d597511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras import metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvXUrmZETR4t",
        "colab_type": "code",
        "outputId": "7c171685-8a91-4ccb-a303-c40fbdc85878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df = pd.read_csv('top200subs.csv')\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>selftext</th>\n",
              "      <th>fulltext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Beautiful Home :)</td>\n",
              "      <td>Home</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Beautiful Home :)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Pretty proud of this clean up project I found ...</td>\n",
              "      <td>Home</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pretty proud of this clean up project I found ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Twins</td>\n",
              "      <td>Home</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>This was finished yesterday..</td>\n",
              "      <td>Home</td>\n",
              "      <td>NaN</td>\n",
              "      <td>This was finished yesterday..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>My roommate is kicking me out because having a...</td>\n",
              "      <td>Home</td>\n",
              "      <td>So, I am not asking for advice, really...mores...</td>\n",
              "      <td>My roommate is kicking me out because having a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9995</td>\n",
              "      <td>Crysis Remastered leaked for Xbox One, PS4, PC...</td>\n",
              "      <td>GamingLeaksAndRumours</td>\n",
              "      <td>\"Crysis Remastered brings new graphic features...</td>\n",
              "      <td>Crysis Remastered leaked for Xbox One, PS4, PC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9996</td>\n",
              "      <td>TLOU 2 delayed indefinitely</td>\n",
              "      <td>GamingLeaksAndRumours</td>\n",
              "      <td>https://twitter.com/jasonschreier/status/12457...</td>\n",
              "      <td>TLOU 2 delayed indefinitelyhttps://twitter.com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9997</td>\n",
              "      <td>Test Drive Unlimited 3 (Project Sunrise) - TDU...</td>\n",
              "      <td>GamingLeaksAndRumours</td>\n",
              "      <td>(Sorry if my english isn't that good)\\n\\nI'm a...</td>\n",
              "      <td>Test Drive Unlimited 3 (Project Sunrise) - TDU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9998</td>\n",
              "      <td>RE8 is called RESIDENT EVIL VILLAGE</td>\n",
              "      <td>GamingLeaksAndRumours</td>\n",
              "      <td>https://twitter.com/Nibellion/status/124746090...</td>\n",
              "      <td>RE8 is called RESIDENT EVIL VILLAGEhttps://twi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>9999</td>\n",
              "      <td>Cyberpunk 2077 Gameplay Leak That Will Not Get...</td>\n",
              "      <td>GamingLeaksAndRumours</td>\n",
              "      <td>There have been many posts about the Cyberpunk...</td>\n",
              "      <td>Cyberpunk 2077 Gameplay Leak That Will Not Get...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                           fulltext\n",
              "0              0  ...                                  Beautiful Home :)\n",
              "1              1  ...  Pretty proud of this clean up project I found ...\n",
              "2              2  ...                                              Twins\n",
              "3              3  ...                      This was finished yesterday..\n",
              "4              4  ...  My roommate is kicking me out because having a...\n",
              "...          ...  ...                                                ...\n",
              "9995        9995  ...  Crysis Remastered leaked for Xbox One, PS4, PC...\n",
              "9996        9996  ...  TLOU 2 delayed indefinitelyhttps://twitter.com...\n",
              "9997        9997  ...  Test Drive Unlimited 3 (Project Sunrise) - TDU...\n",
              "9998        9998  ...  RE8 is called RESIDENT EVIL VILLAGEhttps://twi...\n",
              "9999        9999  ...  Cyberpunk 2077 Gameplay Leak That Will Not Get...\n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ0jrFiDTvbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean(X):\n",
        "\n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # remove '\\\\n'\n",
        "    X['fulltext'] = X['fulltext'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "    X['subreddit'] = X['subreddit'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
        "    \n",
        "    # remove '' \n",
        "    X['fulltext'] = X['fulltext'].map(lambda x: re.sub('<lb>',' ',str(x)))\n",
        "    X['subreddit'] = X['subreddit'].map(lambda x: re.sub('<lb>',' ',str(x)))\n",
        "    \n",
        "    # remove any text starting with User... \n",
        "    X['fulltext'] = X['fulltext'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    X['subreddit'] = X['subreddit'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    \n",
        "    # remove IP addresses or user IDs\n",
        "    X['fulltext'] =X['fulltext'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    X['subreddit'] = X['subreddit'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
        "    \n",
        "    #remove http links in the text\n",
        "    X['fulltext'] = X['fulltext'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
        "    X['subreddit'] = X['subreddit'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JeAFD3eUBfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = clean(df)\n",
        "X_train = df['fulltext']\n",
        "y_train = df['subreddit']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAehjs5-Ulv5",
        "colab_type": "text"
      },
      "source": [
        "##LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WRlX8erUnTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras tokenizer to assign a dictionary for sequences\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojiWtij0dT3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For some reason y_train has to be numeric in this model as well\n",
        "labeler = LabelEncoder()\n",
        "y_train_enc = labeler.fit_transform(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4RUoYRlVVPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sequences\n",
        "X_sequences = t.texts_to_sequences(X_train)\n",
        "\n",
        "# Set the params of the LSTM model\n",
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(t.word_index.values()) + 1\n",
        "\n",
        "# 111 was the average so we will limit it to 100\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "# Pad the sequence to make uniform entries\n",
        "X_seq_pad = sequence.pad_sequences(X_sequences, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAk5FluvU923",
        "colab_type": "code",
        "outputId": "11d97c0b-9d5e-418e-c096-2e215c231fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Find average number of words in each post\n",
        "counter = 0\n",
        "for seq in X_sequences:\n",
        "  counter += len(seq)\n",
        "\n",
        "counter/10000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111.0333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icF1c89Acu7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "# Need this to flatten it to the apt shape\n",
        "model.add(Embedding(max_features, 128))\n",
        "# 128 specified by papers/industry. Dropout and recurrent_dropout set our forget params\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "# multi class prediction of target y_train\n",
        "model.add(Dense(len(y_train), activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='nadam', loss='sparse_categorical_crossentropy',\n",
        "              metrics=['top_k_categorical_accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpv2WIwpc3tz",
        "colab_type": "code",
        "outputId": "92b66036-bc49-429a-9542-38370f755996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model.fit(X_seq_pad, y_train_enc, batch_size=batch_size, epochs=15,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 5.1516 - top_k_categorical_accuracy: 0.0160 - val_loss: 14.3873 - val_top_k_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 5.1452 - top_k_categorical_accuracy: 6.2500e-04 - val_loss: 14.9042 - val_top_k_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 5.1421 - top_k_categorical_accuracy: 0.0000e+00 - val_loss: 14.8754 - val_top_k_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 5.1284 - top_k_categorical_accuracy: 0.1277 - val_loss: 14.0725 - val_top_k_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 5.0707 - top_k_categorical_accuracy: 0.0108 - val_loss: 13.6784 - val_top_k_categorical_accuracy: 0.7395\n",
            "Epoch 6/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 4.8918 - top_k_categorical_accuracy: 0.0436 - val_loss: 13.7449 - val_top_k_categorical_accuracy: 0.0025\n",
            "Epoch 7/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 4.5547 - top_k_categorical_accuracy: 0.0116 - val_loss: 13.9741 - val_top_k_categorical_accuracy: 0.0220\n",
            "Epoch 8/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 4.3564 - top_k_categorical_accuracy: 0.0161 - val_loss: 14.2966 - val_top_k_categorical_accuracy: 0.1245\n",
            "Epoch 9/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 3.7690 - top_k_categorical_accuracy: 0.0377 - val_loss: 14.6178 - val_top_k_categorical_accuracy: 0.0180\n",
            "Epoch 10/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 3.3113 - top_k_categorical_accuracy: 0.0350 - val_loss: 15.0174 - val_top_k_categorical_accuracy: 0.0265\n",
            "Epoch 11/15\n",
            "8000/8000 [==============================] - 12s 2ms/step - loss: 2.9105 - top_k_categorical_accuracy: 0.0334 - val_loss: 15.2235 - val_top_k_categorical_accuracy: 0.0210\n",
            "Epoch 12/15\n",
            "8000/8000 [==============================] - 12s 2ms/step - loss: 2.5692 - top_k_categorical_accuracy: 0.0299 - val_loss: 15.3679 - val_top_k_categorical_accuracy: 0.0320\n",
            "Epoch 13/15\n",
            "8000/8000 [==============================] - 12s 2ms/step - loss: 2.2867 - top_k_categorical_accuracy: 0.0261 - val_loss: 15.5575 - val_top_k_categorical_accuracy: 0.0375\n",
            "Epoch 14/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 2.0561 - top_k_categorical_accuracy: 0.0347 - val_loss: 15.8230 - val_top_k_categorical_accuracy: 0.0170\n",
            "Epoch 15/15\n",
            "8000/8000 [==============================] - 13s 2ms/step - loss: 1.8685 - top_k_categorical_accuracy: 0.0239 - val_loss: 15.9755 - val_top_k_categorical_accuracy: 0.0265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc45c2865f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTHvt6RTjjTm",
        "colab_type": "text"
      },
      "source": [
        "##BERT\n",
        "\n",
        " (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture. Used in google for search. Understands the context. Order and stop words accounted for situationally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys8dyR2uOeD0",
        "colab_type": "code",
        "outputId": "4d0cf037-1ea0-4e95-a91e-548e4bbcdc91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install bert-serving-server  # server\n",
        "!pip install bert-serving-client  # client, independent of `bert-serving-server`"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-serving-server in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (19.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.14.5)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.1.0)\n",
            "Requirement already satisfied: GPUtil>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server) (1.12.0)\n",
            "Requirement already satisfied: bert-serving-client in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (19.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7wUJVPEQbTb",
        "colab_type": "code",
        "outputId": "7d9e4164-8071-4e5a-d345-69b869c00f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip && unzip uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-01 03:48:10--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.11.176, 2607:f8b0:4007:804::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.11.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip.1’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   163MB/s    in 2.4s    \n",
            "\n",
            "2020-05-01 03:48:12 (163 MB/s) - ‘uncased_L-12_H-768_A-12.zip.1’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "replace uncased_L-12_H-768_A-12/bert_model.ckpt.meta? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "replace uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  Y A\n",
            "Y\n",
            "\n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nn8O77eQcYe",
        "colab_type": "code",
        "outputId": "4671712a-e849-4fc0-be4b-c42489cbc6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!bert-serving-start -model_dir uncased_L-12_H-768_A-12/ -num_worker=1 -max_seq_len 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: /usr/local/bin/bert-serving-start -model_dir uncased_L-12_H-768_A-12/ -num_worker=1 -max_seq_len 50\n",
            "                 ARG   VALUE\n",
            "__________________________________________________\n",
            "           ckpt_name = bert_model.ckpt\n",
            "         config_name = bert_config.json\n",
            "                cors = *\n",
            "                 cpu = False\n",
            "          device_map = []\n",
            "       do_lower_case = True\n",
            "  fixed_embed_length = False\n",
            "                fp16 = False\n",
            " gpu_memory_fraction = 0.5\n",
            "       graph_tmp_dir = None\n",
            "    http_max_connect = 10\n",
            "           http_port = None\n",
            "        mask_cls_sep = False\n",
            "      max_batch_size = 256\n",
            "         max_seq_len = 50\n",
            "           model_dir = uncased_L-12_H-768_A-12/\n",
            "no_position_embeddings = False\n",
            "    no_special_token = False\n",
            "          num_worker = 1\n",
            "       pooling_layer = [-2]\n",
            "    pooling_strategy = REDUCE_MEAN\n",
            "                port = 5555\n",
            "            port_out = 5556\n",
            "       prefetch_size = 10\n",
            " priority_batch_size = 16\n",
            "show_tokens_to_client = False\n",
            "     tuned_model_dir = None\n",
            "             verbose = False\n",
            "                 xla = False\n",
            "\n",
            "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: uncased_L-12_H-768_A-12/bert_config.json\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /tmp/tmpr4va97nx\n",
            "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 75]:optimized graph is stored at: /tmp/tmpr4va97nx\n",
            "I:\u001b[35mVENTILATOR\u001b[0m:[__i:_ru:129]:bind all sockets\n",
            "Exception in thread Thread-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bert_serving/server/__init__.py\", line 115, in run\n",
            "    self._run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/decorators.py\", line 75, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/decorators.py\", line 75, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/zmq/decorators.py\", line 75, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bert_serving/server/zmq_decor.py\", line 27, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bert_serving/server/__init__.py\", line 130, in _run\n",
            "    frontend.bind('tcp://*:%d' % self.port)\n",
            "  File \"zmq/backend/cython/socket.pyx\", line 550, in zmq.backend.cython.socket.Socket.bind\n",
            "  File \"zmq/backend/cython/checkrc.pxd\", line 26, in zmq.backend.cython.checkrc._check_rc\n",
            "zmq.error.ZMQError: Address already in use\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/bert-serving-start\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bert_serving/server/cli/__init__.py\", line 4, in main\n",
            "    with BertServer(get_run_args()) as server:\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/bert_serving/server/__init__.py\", line 82, in __enter__\n",
            "    self.is_ready.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYHVCUxKRZSn",
        "colab_type": "code",
        "outputId": "fc65ff68-a111-42bd-a3f7-33bf1319fda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Needs specific tensorflow version\n",
        "!pip install tensorflow==1.10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.10 in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.9.0)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (39.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.28.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.12.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.10.0)\n",
            "Requirement already satisfied: numpy<=1.14.5,>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.14.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuhpgxTzjoF7",
        "colab_type": "code",
        "outputId": "2d3af82d-9ad0-453e-b9b3-4f201a857c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "\n",
        "from bert_serving.client import BertClient\n",
        "\n",
        "# make a connection with the BERT server using it's ip address; do not give any ip if same computer\n",
        "bc = BertClient()\n",
        "# get the embedding\n",
        "embedding = bc.encode([\"I love data science and analytics vidhya.\"])\n",
        "# check the shape of embedding, it should be 1x768\n",
        "print(embedding.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f92e10d48293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make a connection with the BERT server using it's ip address; do not give any ip if same computer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# get the embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"I love data science and analytics vidhya.\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ip, port, port_out, output_fmt, show_server_config, identity, check_version, check_length, check_token_info, ignore_all_checks, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_all_checks\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcheck_version\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshow_server_config\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_length\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheck_token_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0ms_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_version\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms_status\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_version'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'client_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36marg_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVTIMEO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 t_e = TimeoutError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36mserver_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0mreq_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'SHOW_CONFIG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/bert_serving/client/__init__.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, wait_for_req_id)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# receive a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceiver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0many\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mfail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCVMORE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}